name: Collect Congress Data (118–119)

on:
  schedule:
    # Nightly at 09:30 UTC = 02:30 PT
    - cron: "30 9 * * *"
    # Weekly full refresh, Sundays 03:00 PT
    - cron: "00 10 * * 0"
  workflow_dispatch: {}

concurrency:
  group: collect-congress-data
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  collect:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system libs
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y wget python3-dev libxml2-dev libxslt1-dev libz-dev python3-venv jq zip

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install congress tool from GitHub (usc-run)
        run: |
          set -euo pipefail
          python -m venv env
          . env/bin/activate
          pip install --upgrade pip
          pip install "git+https://github.com/unitedstates/congress.git"

      - name: Configure env vars (from secrets or defaults)
        run: |
          set -euo pipefail
          # defaults (can be overridden via repo secrets)
          if [ -n "${{ secrets.CONGRESSES }}" ]; then
            echo "CONGRESSES=${{ secrets.CONGRESSES }}" >> $GITHUB_ENV
          else
            echo "CONGRESSES=118,119" >> $GITHUB_ENV
          fi

          if [ -n "${{ secrets.SESSIONS }}" ]; then
            echo "SESSIONS=${{ secrets.SESSIONS }}" >> $GITHUB_ENV
          else
            echo "SESSIONS=118.2023,118.2024,119.2025" >> $GITHUB_ENV
          fi

          if [ -n "${{ secrets.GCS_BUCKET }}" ]; then
            echo "GCS_BUCKET=${{ secrets.GCS_BUCKET }}" >> $GITHUB_ENV
          else
            echo "GCS_BUCKET=congress-bill-data" >> $GITHUB_ENV
          fi

          if [ -n "${{ secrets.GCS_PREFIX }}" ]; then
            echo "GCS_PREFIX=${{ secrets.GCS_PREFIX }}" >> $GITHUB_ENV
          else
            echo "GCS_PREFIX=congress-data" >> $GITHUB_ENV
          fi

          if [ -n "${{ secrets.MAKE_PUBLIC }}" ]; then
            echo "MAKE_PUBLIC=${{ secrets.MAKE_PUBLIC }}" >> $GITHUB_ENV
          else
            echo "MAKE_PUBLIC=false" >> $GITHUB_ENV
          fi

          if [ -n "${{ secrets.GCP_PROJECT }}" ]; then
            echo "GCP_PROJECT=${{ secrets.GCP_PROJECT }}" >> $GITHUB_ENV
          else
            echo "::error::Missing GCP_PROJECT secret; set it in repo secrets."
            exit 1
          fi

      - name: Ensure data dir
        run: mkdir -p data

      # === VOTES ===
      - name: Decide votes mode (--fast vs full)
        id: votes_mode
        run: |
          set -euo pipefail
          # Scheduled runs: use --fast unless it's the weekly full-refresh window (Sunday 10:00 UTC)
          if [ "${{ github.event_name }}" = "schedule" ]; then
            DOW_HOUR="$(date -u '+%w %H')"   # Sunday=0
            if [ "$DOW_HOUR" = "0 10" ]; then
              echo "mode=full" >> $GITHUB_OUTPUT
            else
              echo "mode=fast" >> $GITHUB_OUTPUT
            fi
          else
            # manual runs -> full
            echo "mode=full" >> $GITHUB_OUTPUT
          fi

      - name: Run votes scraper (sessions 118–119)
        env:
          SESSIONS: ${{ env.SESSIONS }}
        run: |
          set -euo pipefail
          . env/bin/activate
          echo "Running votes scraper for SESSIONS=${SESSIONS}"
          if [ "${{ steps.votes_mode.outputs.mode }}" = "fast" ]; then
            echo "Using --fast"
            usc-run votes --sessions="${SESSIONS}" --fast --log=info
          else
            echo "Full votes run"
            usc-run votes --sessions="${SESSIONS}" --log=info
          fi

      - name: List scraped vote files (debug)
        run: |
          set -euo pipefail
          echo "Listing vote JSON files…"
          find data -type f -path "*/votes/*/*/data.json" | sort | sed 's/^/  /' | head -n 200 || true

      - name: Validate vote files exist (warn/fail)
        run: |
          set -euo pipefail
          COUNT=$(find data -type f -path "*/votes/*/*/data.json" | wc -l | tr -d ' ')
          echo "Found $COUNT vote JSON files"
          if [ "$COUNT" -eq 0 ]; then
            echo "::error::No vote JSON files were generated. Check sessions or network."
            exit 1
          fi

      # === BILLS ===
      - name: Fetch GovInfo BILLSTATUS (118–119)
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run govinfo --bulkdata=BILLSTATUS --congress=${CONGRESSES} --log=info

      - name: Process Bills (118–119)
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run bills --congress=${CONGRESSES} --log=info

      - name: Fetch Bill Text (118–119)
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run billtext --congress=${CONGRESSES} --log=info

      - name: List scraped bill files (debug)
        run: |
          set -euo pipefail
          echo "Listing bill metadata files…"
          find data -type f -path "*/bills/*/data.json" | sort | sed 's/^/  /' | head -n 200 || true
          echo "Listing bill text files…"
          find data -type f -path "*/bills/*/text-versions/*/data.json" | sort | sed 's/^/  /' | head -n 200 || true

      # === MANIFESTS (robust + correct GCS URLs) ===
      - name: Build manifests (votes, bills, billtext) - robust
        env:
          GCS_BUCKET: ${{ env.GCS_BUCKET }}
          GCS_PREFIX: ${{ env.GCS_PREFIX }}
        run: |
          set -euo pipefail
          python - <<'PY'
import json, pathlib, os
base = pathlib.Path("data")
bucket = os.environ.get("GCS_BUCKET", "").rstrip("/")
prefix = os.environ.get("GCS_PREFIX", "").strip("/")

def gather(glob):
    return sorted(str(p).replace("\\\\","/") for p in base.glob(glob) if p.is_file())

manifests = {
  "votes-manifest.json": gather("**/votes/*/*/data.json"),
  "bills-manifest.json": gather("**/bills/*/data.json"),
  "billtext-manifest.json": gather("**/bills/*/text-versions/*/data.json"),
}

for name, files in manifests.items():
    with open(name, "w") as fh:
        json.dump({"files": files}, fh)
    print(f"{name} built: {len(files)} files")

    # Build GCS HTTPS manifest variant (strip leading 'data/' so we don't end up with data/data/...)
    gcs_files = []
    for f in files:
        rel = f[len("data/"):] if f.startswith("data/") else f
        if bucket and prefix:
            gcs_files.append(f"https://storage.googleapis.com/{bucket}/{prefix}/data/{rel}")
        elif bucket:
            gcs_files.append(f"https://storage.googleapis.com/{bucket}/{rel}")
        else:
            gcs_files.append("")
    gcs_name = name.replace(".json", "-gcs.json")
    with open(gcs_name, "w") as fh:
        json.dump({"files": gcs_files}, fh)
    print(f"{gcs_name} built: {len(gcs_files)} files")
PY

      - name: Quick manifest counts (debug)
        run: |
          set -euo pipefail
          echo "Votes files: $(jq '.files | length' votes-manifest.json || echo 0)"
          echo "Bills files: $(jq '.files | length' bills-manifest.json || echo 0)"
          echo "BillText files: $(jq '.files | length' billtext-manifest.json || echo 0)"

      # === GCP auth & upload ===
      - name: Setup gcloud (service account - JSON key)
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ env.GCP_PROJECT }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}

      # ALTERNATIVE AUTH (OIDC / Workload Identity Federation) - uncomment this block and remove the JSON-key step above
      # - id: 'auth'
      #   uses: 'google-github-actions/auth@v1'
      #   with:
      #     workload_identity_provider: 'projects/PROJECT_NUMBER/locations/global/workloadIdentityPools/POOL_ID/providers/PROVIDER_ID'
      #     service_account: 'github-actions-sa@PROJECT_ID.iam.gserviceaccount.com'
      #
      # - name: Setup gcloud (via OIDC)
      #   uses: google-github-actions/setup-gcloud@v1
      #   with:
      #     project_id: ${{ env.GCP_PROJECT }}

      - name: Ensure bucket exists
        run: |
          set -euo pipefail
          gsutil ls -b "gs://${GCS_BUCKET}" >/dev/null 2>&1 || gsutil mb -p "${GCP_PROJECT}" "gs://${GCS_BUCKET}"

      - name: Upload data tree to GCS (preserve paths / incremental)
        run: |
          set -euo pipefail
          PREFIX="${GCS_PREFIX%/}"
          DEST="gs://${GCS_BUCKET}/${PREFIX}/data/"
          echo "Syncing local data/ -> ${DEST}"
          # incremental sync of the 'data' directory into gs://.../<prefix>/data/
          gsutil -m rsync -r data "${DEST}"
          echo "Uploading manifests"
          gsutil cp votes-manifest.json votes-manifest-gcs.json bills-manifest.json bills-manifest-gcs.json billtext-manifest.json billtext-manifest-gcs.json "gs://${GCS_BUCKET}/${PREFIX}/"
          # also upload a ZIP archive (keeps older workflow behaviour)
          mkdir -p out
          zip -r out/congress-data.zip data votes-manifest.json bills-manifest.json billtext-manifest.json
          gsutil cp out/congress-data.zip "gs://${GCS_BUCKET}/${PREFIX}/congress-data.zip"

      - name: (optional) Make uploaded objects public (convenience)
        if: ${{ env.MAKE_PUBLIC == 'true' }}
        run: |
          set -euo pipefail
          PREFIX="${GCS_PREFIX%/}"
          echo "Setting public-read on uploaded objects under gs://${GCS_BUCKET}/${PREFIX}"
          # Prefer IAM (works with uniform bucket-level access)
          gsutil iam ch allUsers:roles/storage.objectViewer "gs://${GCS_BUCKET}"
          # If you prefer ACLs (not recommended with uniform bucket-level access):
          # gsutil -m acl ch -r -u AllUsers:R "gs://${GCS_BUCKET}/${PREFIX}/"

      - name: Verify sample GCS objects exist (warn/fail)
        run: |
          set -euo pipefail
          # adjust samples as needed
          SAMPLES=(
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/data/119/bills/sjres55/data.json"
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/data/119/votes/119-1/vote_119_1_00499/data.json"
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/congress-data.zip"
          )
          MISSING=0
          for s in "${SAMPLES[@]}"; do
            echo "Checking $s"
            if gsutil -q stat "$s"; then
              echo "OK: $s"
            else
              echo "::warning::Missing (or inaccessible) object: $s"
              MISSING=1
            fi
          done
          if [ "$MISSING" -ne 0 ]; then
            echo "::warning::One or more sample objects are missing from GCS (see above)."
            # do not fail the job by default; uncomment to fail instead:
            # exit 1
          fi

      - name: Print summary (sample public URL if public)
        run: |
          set -euo pipefail
          PREFIX="${GCS_PREFIX%/}"
          echo "Uploaded to gs://${GCS_BUCKET}/${PREFIX}/"
          if [ "${MAKE_PUBLIC}" = "true" ]; then
            echo "Public example: https://storage.googleapis.com/${GCS_BUCKET}/${PREFIX}/data/119/bills/sjres55/data.json"
            echo "Archive: https://storage.googleapis.com/${GCS_BUCKET}/${PREFIX}/congress-data.zip"
          else
            echo "Bucket is private; consumers must use GCS credentials or signed URLs to access objects."
          fi
