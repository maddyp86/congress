name: Collect Congress Data (118–119)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "30 9 * * *" # nightly (09:30 UTC)
    - cron: "0 10 * * 0" # weekly full refresh (Sunday 10:00 UTC)

concurrency:
  group: collect-congress-data
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  collect_and_publish:
    runs-on: ubuntu-latest
    timeout-minutes: 240

    # Defaults with secret fallbacks
    env:
      CONGRESSES: ${{ secrets.CONGRESSES || '118,119' }}
      SESSIONS: ${{ secrets.SESSIONS || '118.2023,118.2024,119.2025' }}
      GCS_BUCKET: ${{ secrets.GCS_BUCKET || 'congress-bill-data' }}
      GCS_PREFIX: ${{ secrets.GCS_PREFIX || 'congress-data' }}
      MAKE_PUBLIC: ${{ secrets.MAKE_PUBLIC || 'false' }}
      GCP_PROJECT: ${{ secrets.GCP_PROJECT }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Install system libs
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y python3-venv jq zip

# ==== Python setup + pip cache + install congress tool (usc-run) ====
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install congress tool from GitHub (usc-run)
        run: |
          set -euo pipefail
          python -m venv env
          . env/bin/activate
          python -m pip install --upgrade pip
          pip install "git+https://github.com/unitedstates/congress.git"

      - name: Verify required env
        run: |
          set -euo pipefail
          : "${GCP_PROJECT:?Missing required secret GCP_PROJECT}"
          : "${GCS_BUCKET:?Missing required GCS_BUCKET}"

      - name: Ensure data dir
        run: mkdir -p data

      # === VOTES ===
      - name: Run votes scraper
        env:
          SESSIONS: ${{ env.SESSIONS }}
        run: |
          set -euo pipefail
          . env/bin/activate
          if [ "${{ github.event.schedule }}" = "30 9 * * *" ]; then
            usc-run votes --sessions="${SESSIONS}" --fast --log=info
          else
            usc-run votes --sessions="${SESSIONS}" --log=info
          fi

      - name: Quick votes debug
        run: |
          set -euo pipefail
          echo "Votes files (sample):"
          find data -type f -path "*/votes/*/*/data.json" | sort | sed 's/^/  /' | head -n 100 || true

      # === BILLS (govinfo -> process) ===
      - name: Fetch GovInfo BILLSTATUS
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run govinfo --bulkdata=BILLSTATUS --congress="${CONGRESSES}"

      - name: Process bills
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run bills

      - name: Quick bills debug
        run: |
          set -euo pipefail
          echo "Bill metadata files (sample):"
          find data -type f -path "*/bills/*/data.json" | sort | sed 's/^/  /' | head -n 100 || true

      # === BILL TEXT ===
      - name: Fetch GovInfo BILLS (text) and run billtext
        run: |
          set -euo pipefail
          . env/bin/activate
          usc-run govinfo --collections=BILLS --congress="${CONGRESSES}" --store=mods,xml,text --bulkdata=False
          usc-run billtext

      - name: Quick billtext debug
        run: |
          set -euo pipefail
          echo "Bill text (text-version data.json) sample:"
          find data -type f -path "*/bills/*/text-versions/*/data.json" | sort | sed 's/^/  /' | head -n 100 || true

      # === Build latest_* exports ===
      - name: Build latest_billtext (one most-recent text-version per bill)
        run: |
          set -euo pipefail
          . env/bin/activate
          python - <<'PY'
          import json, pathlib, shutil
          from datetime import datetime, timezone

          base = pathlib.Path("data")
          out = pathlib.Path("latest_billtext")
          if out.exists():
              shutil.rmtree(out)
          out.mkdir(parents=True, exist_ok=True)
          
          def parse_date(s):
              if not s or not isinstance(s, str):
                  return None
              try:
                  if s.endswith("Z"):
                      s = s[:-1] + "+00:00"
                  return datetime.fromisoformat(s)
              except Exception:
                  try:
                      return datetime.fromisoformat(s.split("T")[0])
                  except Exception:
                      return None
          
          def mtime_dt(p):
              try:
                  return datetime.fromtimestamp(p.stat().st_mtime, tz=timezone.utc)
              except Exception:
                  return datetime.fromtimestamp(0, tz=timezone.utc)
          
          for congress_dir in sorted([p for p in base.iterdir() if p.is_dir()]):
              bills_root = congress_dir / "bills"
              if not bills_root.exists():
                  continue
              for bill_dir in sorted([p for p in bills_root.iterdir() if p.is_dir()]):
                  txt_root = bill_dir / "text-versions"
                  if not txt_root.exists():
                      continue
                  best = None
                  for ver in sorted([p for p in txt_root.iterdir() if p.is_dir()]):
                      f = ver / "data.json"
                      if not f.is_file():
                          continue
                      try:
                          obj = json.load(open(f, "r"))
                          dt = parse_date(obj.get("issued_on") or obj.get("issued") or obj.get("date"))
                      except Exception:
                          dt = None
                      dt = dt or mtime_dt(f)
                      cand = (dt, mtime_dt(f), f)
                      if best is None or cand > best:
                          best = cand
                  if best:
                      dest = out / congress_dir.name / "bills" / bill_dir.name
                      dest.mkdir(parents=True, exist_ok=True)
                      shutil.copy2(best[2], dest / "data.json")
                      print(f"picked {best[2]} -> {dest/'data.json'}")
          PY

      - name: Build latest_bills (bill metadata mirror)
        run: |
          set -euo pipefail
          python - <<'PY'
          import pathlib, shutil
          base = pathlib.Path("data")
          out  = pathlib.Path("latest_bills")
          if out.exists():
          shutil.rmtree(out)
            for f in base.rglob("bills/*/data.json"):
            dest = out / f.parent.relative_to(base)
            dest.mkdir(parents=True, exist_ok=True)
            shutil.copy2(f, dest / "data.json")
            print("latest_bills built")
          PY

      # === Manifests (local + GCS URLs that point to /data) ===
      - name: Build manifests (local + gcs URLs)
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, pathlib, os

          base = pathlib.Path("data")
          bucket = os.environ.get("GCS_BUCKET","").rstrip("/")
          prefix = os.environ.get("GCS_PREFIX","").strip("/")

          def gather(pattern):
              # Pattern is relative (e.g., 'votes/*/*/data.json'); search anywhere under base.
              return sorted(str(p).replace("\\","/") for p in base.rglob(pattern) if p.is_file())
          
          manifests = {
            "votes-manifest.json": gather("votes/*/*/data.json"),
            "bills-manifest.json": gather("bills/*/data.json"),
            "billtext-manifest.json": gather("bills/*/text-versions/*/data.json"),
          }

          for name, files in manifests.items():
              with open(name,"w") as fh:
                  json.dump({"files": files}, fh)
              gcs_files = []
              for f in files:
                  rel = f[len("data/"):] if f.startswith("data/") else f
                  if bucket and prefix:
                      gcs_files.append(f"https://storage.googleapis.com/{bucket}/{prefix}/data/{rel}")
                  elif bucket:
                      gcs_files.append(f"https://storage.googleapis.com/{bucket}/{rel}")
                  else:
                      gcs_files.append("")
              gcs_name = name.replace(".json","-gcs.json")
              with open(gcs_name,"w") as fh:
                  json.dump({"files": gcs_files}, fh)
              print(f"{name} built: {len(files)} files; {gcs_name}: {len(gcs_files)} files")
          PY

      - name: Quick manifest counts
        run: |
          set -euo pipefail
          echo "Votes files: $(jq '.files | length' votes-manifest.json || echo 0)"
          echo "Bills files: $(jq '.files | length' bills-manifest.json || echo 0)"
          echo "BillText files: $(jq '.files | length' billtext-manifest.json || echo 0)"

      # === GCP auth + upload ===
      - name: Authenticate to GCP (service account)
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup gcloud (sets project)
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}
          version: '>= 472.0.0'

      - name: Ensure bucket exists
        run: |
          set -euo pipefail
          gsutil ls -b "gs://${GCS_BUCKET}" >/dev/null 2>&1 || gsutil mb -p "${GCP_PROJECT}" "gs://${GCS_BUCKET}"

      - name: Upload data, latest_* & manifests to GCS
        run: |
          set -euo pipefail
          PREFIX="${GCS_PREFIX%/}"

          # Full tree: ALL bills, ALL bill text versions, and ALL votes
          echo "Sync full data -> gs://${GCS_BUCKET}/${PREFIX}/data/"
          gsutil -m rsync -r -d data "gs://${GCS_BUCKET}/${PREFIX}/data"

          # Convenience “latest” folders
          for SRC in latest_billtext latest_bills; do
            if [ -d "$SRC" ]; then
              SUB="${SRC#latest_}"  # billtext or bills
              echo "Uploading $SRC -> gs://${GCS_BUCKET}/${PREFIX}/latest/${SUB}/"
              gsutil -m cp -r "$SRC"/* "gs://${GCS_BUCKET}/${PREFIX}/latest/${SUB}/"
            fi
          done

          echo "Uploading manifests -> gs://${GCS_BUCKET}/${PREFIX}/"
          gsutil cp votes-manifest.json votes-manifest-gcs.json \
                   bills-manifest.json bills-manifest-gcs.json \
                   billtext-manifest.json billtext-manifest-gcs.json \
                   "gs://${GCS_BUCKET}/${PREFIX}/" || true

      - name: Make uploaded objects public (optional)
        if: ${{ env.MAKE_PUBLIC == 'true' }}
        run: |
          set -euo pipefail
          gsutil iam ch allUsers:roles/storage.objectViewer "gs://${GCS_BUCKET}"

      - name: Verify sample objects (warning only)
        continue-on-error: true
        run: |
          set -euo pipefail
          SAMPLES=(
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/data/119/bills/sjres55/data.json"                     # bill metadata
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/latest/billtext/119/bills/sjres55/data.json"        # latest bill text
            "gs://${GCS_BUCKET}/${GCS_PREFIX}/data/119/votes/119-1/vote_119_1_00499/data.json"    # vote record
          )
          for s in "${SAMPLES[@]}"; do
            gsutil -q stat "$s" && echo "OK: $s" || echo "::warning::Missing or inaccessible: $s"
          done

      - name: Summary
        run: |
          set -euo pipefail
          COUNT_TEXT=$(find latest_billtext -type f -name data.json 2>/dev/null | wc -l || true)
          COUNT_BILLS=$(find latest_bills -type f -name data.json 2>/dev/null | wc -l || true)
          echo "Uploaded bucket: ${GCS_BUCKET}"
          echo "Prefix: ${GCS_PREFIX}"
          echo "latest_billtext count: ${COUNT_TEXT}"
          echo "latest_bills count: ${COUNT_BILLS}"
