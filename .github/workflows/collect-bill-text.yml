name: Collect Congress Bill Text (119)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "30 9 * * *" # nightly (09:30 UTC)

concurrency:
  group: collect-congress-billtext-xml
  cancel-in-progress: true

permissions:
  contents: read

env:
  GCS_BUCKET: ${{ secrets.GCS_BUCKET || 'congress-legislative-data' }}
  GCS_PREFIX: ${{ secrets.GCS_PREFIX || 'congress-billtext-xml' }}
  GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
  CONGRESS: "119"
  SESSION: "1"
  BILL_TYPES: "hr s hjres sjres hconres sconres hres sres"

jobs:
  download_billtext:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install deps
        run: sudo apt-get update -y && sudo apt-get install -y jq curl python3

      - name: Fetch bulkdata + normalize
        run: |
          set -euo pipefail
          mkdir -p "data/${CONGRESS}/bills"

          BASE_URL="https://www.govinfo.gov/bulkdata/json/BILLS/${CONGRESS}/${SESSION}"

          for BT in $BILL_TYPES; do
            echo "Fetching $BT..."
            curl -fsSL -H "Accept: application/json" "${BASE_URL}/${BT}" | \
              jq -r '.files[].url' | while read -r URL; do
                [ -z "$URL" ] && continue
                FNAME="$(basename "$URL")"
                BILL_DIR="data/${CONGRESS}/bills/${BT}/${FNAME%.*}"
                mkdir -p "$BILL_DIR"
                DEST="${BILL_DIR}/${FNAME}"
                if [ ! -f "$DEST" ]; then
                  curl -fsSL -o "$DEST" "$URL"
                fi
              done
          done

          # Normalize + manifest
          python3 <<'EOF'
          import pathlib, json, re
          from datetime import datetime, timezone

          base = pathlib.Path("data") / "${CONGRESS}" / "bills"
          rx = re.compile(r"BILLS-(\d+)([a-z]+)(\d+)([a-z]+)\.xml", re.I)
          count = 0

          for xml in base.rglob("*.xml"):
              m = rx.match(xml.name)
              if not m: 
                  continue
              congress, bt, num, version = m.groups()
              bill_id = f"{bt}{int(num)}-{congress}".lower()
              pkg = xml.stem
              urls = {
                  "html": f"https://www.govinfo.gov/content/pkg/{pkg}/html/{pkg}.htm",
                  "pdf":  f"https://www.govinfo.gov/content/pkg/{pkg}/pdf/{pkg}.pdf",
                  "xml":  f"https://www.govinfo.gov/content/pkg/{pkg}/xml/{pkg}.xml",
              }
              meta = {
                  "bill_id": bill_id,
                  "version_code": version.lower(),
                  "issued_on": datetime.fromtimestamp(xml.stat().st_mtime, tz=timezone.utc).strftime("%Y-%m-%d"),
                  "urls": urls,
              }
              (xml.parent/"data.json").write_text(json.dumps(meta, indent=2), encoding="utf-8")
              count += 1

          manifest = {
              "file_count": count,
              "generated_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
              "congress": "${CONGRESS}",
              "session": "${SESSION}"
          }
          pathlib.Path("billtext-manifest.json").write_text(json.dumps(manifest, indent=2), encoding="utf-8")
          print(json.dumps(manifest, indent=2))
          EOF

      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}

      - name: Upload to GCS
        run: |
          gsutil -m rsync -r "data/${CONGRESS}" "gs://${GCS_BUCKET}/${GCS_PREFIX}/data/${CONGRESS}"
          gsutil -m cp -n billtext-manifest.json "gs://${GCS_BUCKET}/${GCS_PREFIX}/manifests/"

      - name: Summary
        run: cat billtext-manifest.json
